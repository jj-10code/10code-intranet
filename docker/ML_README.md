# ü§ñ Machine Learning - Gu√≠a de Desarrollo

Esta gu√≠a es para desarrolladores que trabajan con el m√≥dulo de estimaciones CEPF y Machine Learning.

## üì¶ Dependencias de ML

El proyecto incluye las siguientes dependencias de ML (grupo opcional `[ml]`):

| Librer√≠a | Tama√±o | Uso |
|----------|--------|-----|
| **TensorFlow** | ~2.5GB | Framework principal de ML |
| **PyTorch** | ~2GB | Framework alternativo de ML |
| **scikit-learn** | ~200MB | Algoritmos cl√°sicos de ML |
| **pandas** | ~100MB | Manipulaci√≥n de datos |
| **numpy** | ~50MB | C√°lculo num√©rico |
| **spacy** | ~500MB | Procesamiento de lenguaje natural |
| **transformers** | ~300MB | Modelos preentrenados NLP |
| **nltk** | ~50MB | Toolkit de NLP |

**Total:** ~6GB de dependencias adicionales

## üöÄ Quick Start con ML

### Opci√≥n 1: Setup Completo (Recomendado)

```bash
# Setup inicial con ML (incluye migraciones)
make ml-setup

# Crear superusuario
make createsuperuser
```

### Opci√≥n 2: Agregar ML a Proyecto Existente

```bash
# Si ya tienes el proyecto corriendo sin ML

# 1. Detener servicios actuales
make down

# 2. Build con ML
make ml-build

# 3. Levantar con ML
make ml-up
```

## üõ†Ô∏è Comandos Disponibles

### Gesti√≥n de Servicios con ML

```bash
make ml-build      # Build de im√°genes con ML (tarda ~10-15 min)
make ml-up         # Levantar servicios con ML
make ml-down       # Detener servicios con ML
make ml-logs       # Ver logs de servicios con ML
make ml-setup      # Setup completo desde cero
```

### Desarrollo Normal (Sin ML)

```bash
make build         # Build sin ML (~2-3 min)
make up            # Levantar sin ML
make down          # Detener servicios
```

## üí° Cu√°ndo Usar ML

**‚úÖ Usa `make ml-*` cuando:**
- Desarrollas el m√≥dulo de estimaciones CEPF
- Entrenas o pruebas modelos de ML
- Trabajas con procesamiento de lenguaje natural
- Necesitas TensorFlow o PyTorch

**‚ùå NO necesitas ML para:**
- Desarrollo de frontend
- Trabajo en m√≥dulos de proyectos, recursos, timetracking
- Testing general de la aplicaci√≥n
- Desarrollo de APIs

## ‚è±Ô∏è Tiempos de Build

| Configuraci√≥n | Primera Build | Rebuilds |
|--------------|---------------|----------|
| **Sin ML** (dev) | 2-3 min | 30-60 seg |
| **Con ML** | 10-15 min | 5-10 min |

üí° **Tip:** Los rebuilds son m√°s r√°pidos gracias al cache de Docker y uv.

## üìä Uso de Recursos

### Requisitos M√≠nimos para ML

- **RAM:** 8GB (16GB recomendado)
- **Disco:** 10GB libres para im√°genes Docker
- **CPU:** 4 cores (8 cores recomendado)

### Configurar Memoria de Docker

Si usas Docker Desktop, aumenta la memoria asignada:

1. Docker Desktop ‚Üí Settings ‚Üí Resources ‚Üí Memory
2. Aumentar a m√≠nimo 6GB (8GB recomendado)
3. Apply & Restart

## üîÑ Workflow de Desarrollo

### Desarrollo Sin ML (Mayor√≠a del Tiempo)

```bash
# D√≠a a d√≠a sin ML
make up
make logs-web
make test
```

### Cuando Necesites ML

```bash
# Cambiar a modo ML
make down
make ml-up

# Tu c√≥digo de ML aqu√≠...

# Volver a modo normal
make down
make up
```

## üêç Verificar Instalaci√≥n de ML

```bash
# Acceder al contenedor
make bash-web

# Verificar que ML est√° instalado
python -c "import tensorflow as tf; print(f'TensorFlow {tf.__version__}')"
python -c "import torch; print(f'PyTorch {torch.__version__}')"
python -c "import sklearn; print(f'scikit-learn {sklearn.__version__}')"

# Salir
exit
```

## üìù Notas Importantes

### GPU Support

Por defecto, las im√°genes usan **CPU only**. Para usar GPU:

1. Instalar [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
2. Modificar `compose.ml.yml` para agregar soporte GPU:

```yaml
services:
  web:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
```

### Modelos Preentrenados

Los modelos de spacy y transformers se descargan la primera vez:

```bash
# Dentro del contenedor
python -m spacy download es_core_news_sm  # Modelo espa√±ol
python -m spacy download en_core_web_sm   # Modelo ingl√©s
```

### Cache de uv

El cache de uv acelera rebuilds. Para limpiar si hay problemas:

```bash
docker builder prune --filter type=exec.cachemount
```

## üîß Troubleshooting

### Build Muy Lento

- **Causa:** Descarga de TensorFlow/PyTorch
- **Soluci√≥n:** Usar cache de Docker, esperar primera vez
- **Tip:** Compilar en horarios de buena conexi√≥n

### Error de Memoria

- **Causa:** Docker con poca RAM
- **Soluci√≥n:** Aumentar memoria en Docker Desktop a 8GB

### M√≥dulo No Encontrado

```bash
# Verificar que construiste con ML
docker compose -f compose.yml -f compose.override.yml -f compose.ml.yml ps

# Si dice que no tiene ML, rebuild
make ml-build
```

## üìö Referencias

- [TensorFlow Docs](https://www.tensorflow.org/)
- [PyTorch Docs](https://pytorch.org/)
- [scikit-learn Docs](https://scikit-learn.org/)
- [spaCy Docs](https://spacy.io/)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)

---

**Desarrollado con üíô por 10Code Team**
